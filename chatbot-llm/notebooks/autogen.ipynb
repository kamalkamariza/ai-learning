{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from autogen import AssistantAgent, UserProxyAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "My name is bob\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Nice to meet you, Bob! How can I assist you today?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'My name is bob', 'role': 'assistant'}, {'content': 'Nice to meet you, Bob! How can I assist you today?', 'role': 'user'}, {'content': '', 'role': 'assistant'}, {'content': 'TERMINATE', 'role': 'user'}], summary='', cost={'usage_including_cached_inference': {'total_cost': 0.00426, 'gpt-4-0613': {'cost': 0.00426, 'prompt_tokens': 108, 'completion_tokens': 17, 'total_tokens': 125}}, 'usage_excluding_cached_inference': {'total_cost': 0.00426, 'gpt-4-0613': {'cost': 0.00426, 'prompt_tokens': 108, 'completion_tokens': 17, 'total_tokens': 125}}}, human_input=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "llm_config = {\n",
    "    \"model\": \"gpt-4\", \n",
    "    \"api_key\": os.environ[\"OPENAI_API_KEY\"],\n",
    "    \"temperature\": 0\n",
    "}\n",
    "\n",
    "assistant = AssistantAgent(\n",
    "    name=\"assistant\", \n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=5,\n",
    "    system_message=\"You are a smart chatbot, reply TERMINATE if you think you have answered user's question or if the user is sending empty message.\"\n",
    ")\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=5,\n",
    "    system_message=\"You are going to ask question one time only, reply TERMINATE if you think your question has a reaction\",\n",
    "    is_termination_msg=lambda content: \"TERMINATE\" in content[\"content\"]\n",
    "    \n",
    ")\n",
    "\n",
    "# Start the chat\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"My name is bob\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "What is my name?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "As an AI, I don't have access to personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality. TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'What is my name?', 'role': 'assistant'}, {'content': \"As an AI, I don't have access to personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality. TERMINATE\", 'role': 'user'}], summary=\"As an AI, I don't have access to personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality. \", cost={'usage_including_cached_inference': {'total_cost': 0.00798, 'gpt-4-0613': {'cost': 0.00798, 'prompt_tokens': 152, 'completion_tokens': 57, 'total_tokens': 209}}, 'usage_excluding_cached_inference': {'total_cost': 0.00798, 'gpt-4-0613': {'cost': 0.00798, 'prompt_tokens': 152, 'completion_tokens': 57, 'total_tokens': 209}}}, human_input=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"What is my name?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for message in history:\n",
    "#     user_proxy.send(message, assistant, request_reply=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class ResumableGroupChatManager(GroupChatManager):\n",
    "#     groupchat: GroupChat\n",
    "\n",
    "#     def __init__(self, groupchat, history, **kwargs):\n",
    "#         self.groupchat = groupchat\n",
    "#         if history:\n",
    "#             self.groupchat.messages = history\n",
    "\n",
    "#         super().__init__(groupchat, **kwargs)\n",
    "\n",
    "#         if history:\n",
    "#             self.restore_from_history(history)\n",
    "\n",
    "#     def restore_from_history(self, history) -> None:\n",
    "#         for message in history:\n",
    "#             # broadcast the message to all agents except the speaker.  This idea is the same way GroupChat is implemented in AutoGen for new messages, this method simply allows us to replay old messages first.\n",
    "#             for agent in self.groupchat.agents:\n",
    "#                 if agent != self:\n",
    "#                     self.send(message, agent, request_reply=False, silent=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
