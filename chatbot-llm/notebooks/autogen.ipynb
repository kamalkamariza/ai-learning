{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import autogen\n",
    "from dotenv import load_dotenv\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from sqlalchemy import create_engine, inspect, MetaData\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "from autogen import AssistantAgent, UserProxyAgent, ConversableAgent, register_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"../.env\")\n",
    "\n",
    "LEAF_TABLE_NAME = \"form_127\"\n",
    "LEAF_DB_NAME = \"eform_data\"\n",
    "LEAF_DB_USER = \"kamalleaf\"\n",
    "LEAF_DB_PASS = os.getenv(\"LEAF_DB_PASS\")\n",
    "LEAF_DB_HOST = \"13.214.63.7\"\n",
    "\n",
    "llm_config = {\n",
    "    \"model\": \"gpt-4\",\n",
    "    \"api_key\": os.environ[\"OPENAI_API_KEY\"],\n",
    "    \"temperature\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Chat - Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assistant = AssistantAgent(\n",
    "#     name=\"assistant\",\n",
    "#     llm_config=llm_config,\n",
    "#     human_input_mode=\"NEVER\",\n",
    "#     max_consecutive_auto_reply=5,\n",
    "#     system_message=\"You are a smart chatbot, reply TERMINATE if you think you have answered user's question or if the user is sending empty message.\",\n",
    "#     is_termination_msg=lambda content: \"TERMINATE\" in content[\"content\"]\n",
    "#     or not content.get(\"content\", \"\"),\n",
    "# )\n",
    "# user_proxy = UserProxyAgent(\n",
    "#     name=\"user_proxy\",\n",
    "#     code_execution_config=False,\n",
    "#     human_input_mode=\"NEVER\",\n",
    "#     max_consecutive_auto_reply=5,\n",
    "#     system_message=\"You are going to ask question one time only, reply TERMINATE if you think your question has a reaction\",\n",
    "#     is_termination_msg=lambda content: \"TERMINATE\" in content[\"content\"],\n",
    "# )\n",
    "\n",
    "# # Start the chat\n",
    "# user_proxy.initiate_chat(\n",
    "#     assistant,\n",
    "#     message=\"My name is bob\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for message in history:\n",
    "#     user_proxy.send(message, assistant, request_reply=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ResumableGroupChatManager(GroupChatManager):\n",
    "#     groupchat: GroupChat\n",
    "\n",
    "#     def __init__(self, groupchat, history, **kwargs):\n",
    "#         self.groupchat = groupchat\n",
    "#         if history:\n",
    "#             self.groupchat.messages = history\n",
    "\n",
    "#         super().__init__(groupchat, **kwargs)\n",
    "\n",
    "#         if history:\n",
    "#             self.restore_from_history(history)\n",
    "\n",
    "#     def restore_from_history(self, history) -> None:\n",
    "#         for message in history:\n",
    "#             # broadcast the message to all agents except the speaker.  This idea is the same way GroupChat is implemented in AutoGen for new messages, this method simply allows us to replay old messages first.\n",
    "#             for agent in self.groupchat.agents:\n",
    "#                 if agent != self:\n",
    "#                     self.send(message, agent, request_reply=False, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SQL query and reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LC_DB:\n",
    "    def __init__(self) -> None:\n",
    "        self.db = SQLDatabase.from_uri(\n",
    "            f\"mysql+mysqlconnector://{LEAF_DB_USER}:{LEAF_DB_PASS}@{LEAF_DB_HOST}/{LEAF_DB_NAME}\",\n",
    "            ignore_tables=set(\n",
    "                [\"eform_titles\", \"form_data_testing\", \"form_127\", \"form_170\"]\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_db = LC_DB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "\n",
    "\n",
    "def get_form_titles():\n",
    "    query = lc_db.db.run(\"SELECT * FROM eform_titles\")\n",
    "    title_list = ast.literal_eval(query)\n",
    "    return title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "\n",
    "# Operator = Literal[\"form_131\", \"form_155\", \"form_156\", \"form_158\", \"form_171\"]\n",
    "\n",
    "\n",
    "def get_table_info(tablename: str) -> str:\n",
    "    try:\n",
    "        return lc_db.db.get_table_info([tablename])\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "\n",
    "def run_query(query: str) -> str:\n",
    "    try:\n",
    "        return lc_db.db.run(query)\n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_writer = ConversableAgent(\n",
    "    \"query_writer\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False,\n",
    "    # code_execution_config={\n",
    "    #     \"executor\": autogen.coding.LocalCommandLineCodeExecutor(work_dir=\"coding\")\n",
    "    # },\n",
    "    system_message=f\"\"\"\n",
    "    You are good at writing SQL queries.\n",
    "    Below are the table names and their entities for you to lookup to.\n",
    "    'form_131' - related to meeting minutes,\n",
    "    'form_145' - related to Incident report,\n",
    "    'form_155' - related to Water Supply Check List,\n",
    "    'form_156' - related to Weekly Audio Visual Checklist - Ballroom SCCC1,\n",
    "    'form_158' - related to Gym Room Checklist,\n",
    "    'form_171' - related to Loan Form Setia\n",
    "    'form_172' - related to Owner / Tenant Registration Form\n",
    "\n",
    "    Write a SQL query based on the tables info returned by get_table_info()\n",
    "    For each of these forms, take note of their correct references as below:\n",
    "    1. 'form_131'\n",
    "        - 'tf_MeetingMinuteSubject' identifies the type of meeting for this data entry. For example if user query for LEAF meeting, find a meeting where 'tf_MeetingMinuteSubject' == LEAF meeting\n",
    "    Respond with TERMINATE after you have returned an aswer\n",
    "    \"\"\",\n",
    "    # is_termination_msg=check_termination,\n",
    "    # is_termination_msg=lambda content: not content.get(\"content\")\n",
    "    # or \"TERMINATE\" in content.get(\"content\"),\n",
    ")\n",
    "\n",
    "reporter = ConversableAgent(\n",
    "    name=\"reporter\",\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    system_message=\"\"\"\n",
    "    You have a data entry from database.\n",
    "    Make sure to answer the user's question regarding the to the data.\n",
    "    If the user enquiry summary, summarise them the content of the data\n",
    "    return TERMINATE after you have all the relevant answer to return.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "user_proxy = ConversableAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=5,\n",
    "    code_execution_config=False,\n",
    "    # code_execution_config={\n",
    "    #     \"executor\": autogen.coding.LocalCommandLineCodeExecutor(work_dir=\"coding\")\n",
    "    # },\n",
    "    is_termination_msg=lambda content: \"TERMINATE\" in content.get(\"content\"),\n",
    ")\n",
    "\n",
    "register_function(\n",
    "    get_table_info,\n",
    "    caller=sql_writer,  # The assistant agent can suggest calls to the calculator.\n",
    "    executor=user_proxy,  # The user proxy agent can execute the calculator calls.\n",
    "    name=\"get_table_info\",  # By default, the function name is used as the tool name.\n",
    "    description=\"Use to describe a table info in a database\",  # A description of the tool.\n",
    ")\n",
    "\n",
    "register_function(\n",
    "    run_query,\n",
    "    caller=sql_writer,  # The assistant agent can suggest calls to the calculator.\n",
    "    executor=user_proxy,  # The user proxy agent can execute the calculator calls.\n",
    "    name=\"run_sql_query\",  # By default, the function name is used as the tool name.\n",
    "    description=\"Use to run a sql command\",  # A description of the tool.\n",
    ")\n",
    "\n",
    "groupchat = autogen.GroupChat(\n",
    "    agents=[user_proxy, sql_writer, reporter], messages=[], max_round=50\n",
    ")\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    manager, message=\"Summarise the 2nd LEAF meeting?\", clear_history=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For RAG agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recur_spliter = RecursiveCharacterTextSplitter(separators=[\"\\n\", \"\\r\", \"\\t\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "#     api_key=os.environ[\"OPENAI_API_KEY\"],  # model_name=\"text-embedding-ada-002\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assistant = RetrieveAssistantAgent(\n",
    "#     name=\"assistant\",\n",
    "#     system_message=\"You are a helpful assistant.\",\n",
    "#     llm_config=llm_config,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ragproxyagent = RetrieveUserProxyAgent(\n",
    "#     name=\"ragproxyagent\",\n",
    "#     retrieve_config={\n",
    "#         \"task\": \"qa\",\n",
    "#         \"docs_path\": [\n",
    "#             \"../data/management/360/360_1715156298.pdf\",\n",
    "#             # \"https://raw.githubusercontent.com/microsoft/autogen/main/README.md\"\n",
    "#         ],\n",
    "#         \"embedding_function\": openai_ef,\n",
    "#         \"custom_text_split_function\": recur_spliter.split_text,\n",
    "#         \"collection_name\": \"360_management\",\n",
    "#         \"get_or_create\": True,\n",
    "#     },\n",
    "#     code_execution_config=False,\n",
    "#     human_input_mode=\"NEVER\",\n",
    "#     # code_execution_config={\n",
    "#     #     \"executor\": autogen.coding.LocalCommandLineCodeExecutor(work_dir=\"coding\")\n",
    "#     # },\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ragproxyagent.initiate_chat(\n",
    "#     assistant,\n",
    "#     message=ragproxyagent.message_generator,\n",
    "#     problem=\"How to set up alarm system?\",\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
